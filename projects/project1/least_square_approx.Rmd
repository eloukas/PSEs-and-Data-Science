---
title: "Least Squares Approximation"
output: html_notebook
---



```{r}
library("MASS")
data = read.table("data.txt")
data = as.matrix(data)
```

# Least Square Approx
```{r}
x = as.matrix(data[,1])
y = as.matrix(data[,2])
phi = matrix(c(x^0,x^1), nrow=dim(data)[1], ncol=dim(data)[2])
w = ginv(phi)%*%y
plot(x,y)
y_approx = phi%*%w
lines(x,y_approx,col="green")
```

# Square Test
```{r}
y_mean = mean(y)
x_mean = mean(x)

SStot = sum((y-y_mean)**2)
SSres = sum((y-y_approx)**2)
r = 1 - (SSres/SStot)
```

# Cross-validation
```{r}
library("MASS")
fold = 8
dimension_row = dim(data)[1]
n = dim(data)[1]/fold
tmp = runif(dimension_row,1,dimension_row)
I = order(tmp)

group_start = 1
for (i in 1:fold){
  group_end = i*n
  test_set_indices = I[group_start:group_end]
  training_set_indices = setdiff(I,test_set_indices)
  
  test_set = data[test_set_indices,]
  training_set = data[training_set_indices,]
  
  x_test = test_set[,1]
  y_test = test_set[,2]

  x_train = training_set[,1]
  y_train = training_set[,2]
  
  phi_train = matrix(c(x_train^0,x_train^1), nrow = dimension_row-n , ncol = 2) # Do the regression
  w = ginv(phi_train)%*%y_train

  # Now we have learned the weights from the training data.
  # We need to determine how well these learned weights work for
  # the unseen test set points.

  phi_test = matrix(c(x_test^0,x_test^1), nrow = n , ncol = 2) 
  y_test_predicted = phi_test%*%w # Find the estimates of y_test

  MSE[i] =   sum((y_test-y_test_predicted)^2)/length(y_test)
  group_start = group_end + 1
}
hist(MSE)
```